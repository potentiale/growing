# 认识爬虫

## 1、HTTP和HTTPS

商业应用

- c/s 即 client server 客户端 服务端（LOL、穿越火线、吃鸡）
- b/s 即 browser server 浏览器服务端（淘宝、网页）
- m/s 即 moblie server 移动端服务端（app、王者荣耀）

以上结构，本质上是客户端和服务端数据的交互。

客户端：安装在本地电脑，为用户提供图形演示效果，提供本地数据输出输入。

服务端：提供数据服务的公司机房的某台服务器上边的服务端程序。

应用层基于TCP/IP协议和各种应用层传输协议FTP。

### HTTP

超文本传输协议

基于TCP / IP通信协议来传递数据（HTML、图片、查询结果等）。

#### HTTP请求流程

Client   ----请求--->   server

​             <----相应---               端口80

url：全球统一资源定位符。

`http://www.aspxfans.com:8080/new/index.asp?boradID=5&ID=24618&page=1#name`

发送HTTP请求==打电话

##### Q1:怎么发送请求的？

```python
# 暂时只听，不要跟着操作
import socket
# 创建socket服务端
server = socket.socket()
# 绑定IP和端口
server.bind(('0.0.0.0',8080))
# 监听
server.listen(5)
# 接收
conn,addr = server.accept()
# 接收数据
data = conn.recv(1024)
print(data)
# 使用浏览器访问127.0.0.1:8080  程序端接收HTTP请求
------------------------
b'GET / HTTP/1.1\r\nHost: 127.0.0.1:8080\r\nConnection:...
```

##### Q2:请求头？

```
Host：请求头。一定要带
User-Agant：访问的设备。告知访问设备
Accept：可接受的信息
Cookie：会话技术
Referer：出处。我从那儿来

```

#### 请求正文

```python
# 创建一个socket服务端
server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
 # socket.socket(socket_family, socket_type, protocol=0)
    # socket_family 可以是 AF_UNIX(基于文件类型的套接字家族) 或 AF_INET(基于网络类型的套接字家族)。
    # socket_type 可以是 SOCK_STREAM 或 SOCK_DGRAM。
    # protocol 一般不填,默认值为 0。
# 绑定ip和端口
server.bind(('0.0.0.0', 8080))
# 监听
server.listen(5)  # 最大连接数量
# 等待连接
while True:
    conn, addr = server.accept()  # 被动接受TCP客户端连接,(阻塞式)等待连接的到来
    # print(conn, addr)
    # 接受数据
    data = conn.recv(1024)

    print(data)
    # 返回响应字节数据
    conn.send('HTTP/1.1 200 ok\r\nContent-Type: text/html;charset=utf-8\r\n\r\n <h1 style="color:red">hello world</h1>'.encode())
    conn.close()
```

#### HTTP响应

(**send**)

四部分：状态行、消息报头、空行、响应正文

#### HTTP 响应状态码

https://www.cnblogs.com/xflonga/p/9368993.html

200-成功

301-重定向

403-被禁用

404-错误，资源不存在

503-服务器错误

#### HTTP响应报头

**Allow**：服务脂支持哪些请求方法（如GET、POST等）。

**Date**：表示消息发送的时间，时间的描述格式由rfc822定义。例如，Date:Mon，31Dec200104：25：57GMT。Date描述的时间表示世界标准时，换算成本地时间，需要知道用户所在的时区。

**Set-Cookie**：非常重要的header，用于把cookie发送到客户端浏览器，每一个写入cookie都会生成一个Set-Cookie。

**Expires**：指定Response的过期时间，从而不再缓存它，重新从服务器获取，会更新缓存。过期之前使用本地缓存。降低服务器负载，缩短加戴时间。

**Content-Type**： WEB服务器告诉客户端自己响应的对象的类型和字符集。

**Accept-Encoding** 和**Content-Encoding**：采用的正文传输编码格式

#### HTTP协议的特点

- 无连接：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。
- 媒体独立：server和client约定好怎么处理。数据内容没有限制。
- 无状态：不会记录客户端信息。每次请求都是独立的。早期互联网带宽不大，大部分是静态页面，对现在的环境有大量的HTTP请求，是一种障碍。

### HHTPS

HTTPS（全称：Hyper Text Transfer Protocol over Secure Socket Layer 或 Hypertext Transfer Protocol Secure，超文本传输安全协议），是以安全为目标的HTTP通道，简单讲是HTTP的安全版
http协议是基于tcp/ip协议的，而https是在http协议的基础之上，再加了一层 SSL/TLS 协议，数据在传输过程中是加密的。
HTTPS 协议的默认端口是443

`HTTP信息明文传输。安全性差`

使用HTTPS服务端必须安装证书。CA公司购买，传输数据之前先验证，之后建立通道。数据都是密文。

#### SSL/TLS 协议

SSL“安全套接层”（使用非对称和对称加密）协议

TLS“安全传输层”协议（）都属于是加密协议。

OSI（分层网络架构）模型，在应用层和传输层之间使用SSL协议。其最广泛的用途之一是在HTTP协议，从而产生HTTPS加密协议。



## 2、爬虫概念

什么是爬虫？

爬虫的概念：网络爬虫也叫网络蜘蛛，它特指一类自动批量下载网络资源的程序，这是一个比较口语化的定义。
更加专业和全面对的定义是：网络爬由是伪装成客户端与服务端进行数据交互的程序。

爬虫有什么用？

1. 数据采集
2. 搜索引擎
3. 模拟操作

### 重点难点

1. 数据的获取。图灵测试，反爬。
2. 采集速度。并发、分布式。

#### 案例

```python
import socket
# 创建客户端
client = socket.socket()

# socket.socket(socket_family, socket_type, protocol=0)
# socket_family 可以是 AF_UNIX(基于文件类型的套接字家族) 或 AF_INET(基于网络类型的套接字家族)。
# socket_type 可以是 SOCK_STREAM 或 SOCK_DGRAM。
# protocol 一般不填,默认值为 0。

# 连接百度服务器
client.connect(('www.baidu.com', 80))
# client.connect_ex()
# 构造http请求报文
data = b'GET / HTTP/1.0\r\nHost:www.baidu.com\r\n\r\n'
# 发送报文
client.send(data)
res = b''
# 接收相应数据
temp = client.recv(4096)

while temp:
    print('**********')
    res += temp
    # print(temp)
    temp = client.recv(4096)

    print(res)
    # print(len(re.findall(b'\r\n\r\n(.*)', data, re.S)[0]))
```



## 3、会话技术

web开发会深入学习

### Cookie

HTTP无状态，服务端不能区分两次请求是同一个用户的。不断的重新提交表单信息。

服务端要给用户请求打标签（门票、令牌）。响应中添加setCookie（键值对（session：个人的ID号））保存在客户端的本地，浏览器完成。——服务端设置cookie响应，客户端保存cookie到本地（浏览器完成）。

去银行不带银行卡，就算柜员是你老婆，她也不敢给你取钱。

很多的网站密码存放在Cookie中实现免登录。**不安全**的方式，在使用金钱的网站的时候一定退出。

### session

会话

一次会话：网站开始到窗口关闭。

意义：在会话期间内的所有操作有效的保存在服务器。

实现客户端的状态识别。因此，**session是基于Cookie的**。

![session](https://images2015.cnblogs.com/blog/1104082/201702/1104082-20170210212817682-1075777716.png)

在用户1和用户2登录的时候，我们的服务器在他们登录成功后，在session表中为他们每个用户分配了一个sessionid并且存下了一个对应的信息。当用户第二次访问该服务器的时候，会将sessionid在request请求中携带者发送过去。这时我们的服务器就可以根据sessionid确定用户存储的数据，然后进行使用。如图所示：

![session](https://images2015.cnblogs.com/blog/1104082/201702/1104082-20170210214818072-725308163.png)

####  session的生命周期

​     当session超过一定时间（一般为30分钟）没有被访问时，服务器就会认为这个session对应的客户端已经停止活动，然后将这个session删除。用以节省空间。当用户关闭浏览器时，sessionId的信息会丢失，虽然服务器session还在，依然无法访问到session中的数据。



### Cookie 和 Session 的区别

Cookie：保存在客户端

Session：保存在服务器。由客户端传上来的SessionID来进行判定，安全性高。

Python实现session技术。

## 4、socket

**Google进行HTTP抓包：背景网。**

```
https://baijiahao.baidu.com/s?id=1612392982674092834&wfr=spider&for=pc
General:一般信息：
	URL:请求的URL
	Method:请求方法
	status Code:304 缓存
	Remote Address:远程地址(HTTP:80,HTTPS:443)
	Remote Policy:
Response Headers:
	accept:接收信息
	accept-Encoding:接收编码格式
    accept-language：接收语言类型
    cache-control：缓存控制
    cookie：键值对
    Host:域名
    user-agent：用户代理
Request Headers:
	
```

**第一个请求的一定是 HTML 页面**

https://www.2717.com/

**socket下载一张图片**

```
1、找到这个图片的请求。图片一定是在服务器下载回来的。
2、IMG 选项
3、查找图片 Preview
```

新建 download_a_img_by_socket.py 文件

```python
"""
利用socket下载一张图片
"""
import socket
# 创建一个socket
client1=socket.socket()# HTTP
client= ssl.wrap_socket(socket.socket())# HTTPS
# img_url 图片的URl要先知道   headers
img_url = "https://t1.hddhhn.com/uploads/tu/201905/406/14g54fd.jpg"
img_url1 = "http://pic.sc.chinaz.com/Files/pic/pic9/201711/zzpic8419_s.jpg"
# 可以直接发送Http请求吗？  先构造HTTP请求报文
# 请求方式  路径(询问)  协议/1.1\r\n报头(Host)
data = "GET /uploads/tu/201905/406/14g54fd.jpg HTTP/1.1\r\nHost: t1.hddhhn.com\r\n\r\n"
# 连接服务端
client.connect(('t1.hddhhn.com', 443))# Https
client1.connect(('pic.sc.chinaz.com', 80))# Http
# 发送请求
client.send(data.encode())
# 接收图片信息变量
img_data = b''
# 接收响应 第一次
while True:
	res = cilent.recv(1024)
	print(res)
```

##### 响应怎么处理直接保存

conent-Length：数据的大小。判断信息

```python
"""
利用socket下载一张图片
"""
import socket
# 创建一个socket
# client1=socket.socket()# HTTP
client= ssl.wrap_socket(socket.socket())# HTTPS
# img_url 图片的URl要先知道   headers
img_url = "https://t1.hddhhn.com/uploads/tu/201905/78/4578hgjk.jpg"
"http://pic.sc.chinaz.com/Files/pic/pic9/201711/zzpic8419_s.jpg"
# 可以直接发送Http请求吗？  先构造HTTP请求报文
# 请求方式  路径(询问)  协议/1.1\r\n报头(Host)
data = "GET /uploads/tu/201905/78/4578hgjk.jpg HTTP/1.1\r\nHost: t1.hddhhn.com\r\n\r\n"
# 连接服务端
client.connect(('t1.hddhhn.com', 443))# Https
# client1.connect(('pic.sc.chinaz.com', 80))# Http
# 发送请求
client.send(data.encode())
# 接收响应
# 第一次数据
img_first_data = client.recv(1024)# win最多只能收1024
# print(img_first_data) # \r\n\e\n之后的都是我们的内容
# 我们先拿长度响应数据内容的长度：必须提供。否则不知道什么时候响应结束
length = int(re.findall(b'Content-Length: (.*?)\r\n',img_first_data)[0])
# print(length)
# 获取图片数据
img_data = b''
# 获取第一次请求里的图片数据，根据\r\n\r\n
img_data += re.findall(b'\r\n\r\n(.*)', img_first_data, re.S)[0]
# print(img_first_data)
# 获取剩余的数据
while True:
    temp = client.recv(1024)
    if temp:
        img_data += temp
    else:
        break
    if len(img_data) >= length: # 数据接收完成
        break
print(len(img_data),length)
# 写文件
with open('test.jpg','wb') as f:
    f.write(img_data)

# while True:
#     res = client.recv(1024)
#     if res:
#         print(res)
#     else:
#         break
```

















